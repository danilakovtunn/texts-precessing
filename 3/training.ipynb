{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PALmYNpw8-zR"
      },
      "source": [
        "# Установка нужных модулей и их импорт"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN7TgRjS87zj",
        "outputId": "f4910203-a2cf-446d-ea31-dbda340ebdfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d4nTep4b9EVd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "import lzma\n",
        "\n",
        "from collections import Counter\n",
        "from transformers.modeling_utils import unwrap_model\n",
        "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForTokenClassification\n",
        "from typing import Tuple, List, Dict, Any\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYN-jDyD9Y7K"
      },
      "source": [
        "# Переход в рабочую директорию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tquDeE4r9G4g",
        "outputId": "0e8e1ba1-b201-416f-da4d-788c82017a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YcjIRggI9e98"
      },
      "outputs": [],
      "source": [
        "os.chdir('drive/MyDrive/text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X99DjMAJ96Un"
      },
      "source": [
        "# Загрузка исходных данных датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Y-Xkx-C9yrD"
      },
      "outputs": [],
      "source": [
        "# !wget https://github.com/nerel-ds/NEREL/releases/download/1.1/NEREL-v1.1.zip -O /content/drive/MyDrive/text/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y2nk0vqI92sm"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/text/archive.zip -d /content/drive/MyDrive/text/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8AwUjVZAeKL"
      },
      "source": [
        "# Функции для обработки датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDDxw25JA2nr"
      },
      "source": [
        "#### Считывание из txt-файла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nZ1hUqa3-7b_"
      },
      "outputs": [],
      "source": [
        "def txt_read(file):\n",
        "    with open(file, 'r') as f:\n",
        "        data = f.read()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw8iJrIlA5eH"
      },
      "source": [
        "#### Считывание из ann-файлы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp8kLzaYBbtA"
      },
      "source": [
        "Из ann-файла нам нужны только метки, начало и конец, причем выкинем из него вложенные сущености, оставим только непересекающиеся внешние"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ERM7t5ibA93I"
      },
      "outputs": [],
      "source": [
        "def ann_read(file):\n",
        "    lst = []\n",
        "    with open(file, 'r') as g:\n",
        "        for string in g.readlines():\n",
        "            if string[0] == 'T' and ';' not in string:\n",
        "                string = string.split()\n",
        "                lst.append((string[1], int(string[2]), int(string[3])))\n",
        "    \n",
        "    lst.sort(key=lambda x: [x[1], -x[2]])\n",
        "    end = -1\n",
        "    ans = []\n",
        "    for i in lst:\n",
        "        if end < i[1]:\n",
        "            ans.append(i)\n",
        "            end = i[2]\n",
        "\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8ebgq3WDX4j"
      },
      "source": [
        "#### Создание BIO-разметки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "inXwNfM3DYSn"
      },
      "outputs": [],
      "source": [
        "def bio(txt, ann, tokenizer):\n",
        "    txt = txt_read(txt)\n",
        "    ann = ann_read(ann)\n",
        "    spans = tokenizer(txt, return_offsets_mapping=True, add_special_tokens=False, truncation=True)['offset_mapping']\n",
        "    tokens = [txt[i[0]:i[1]] for i in spans]\n",
        "    bio_labels = []\n",
        "    for i in spans:\n",
        "        for j in ann:\n",
        "            if i[0] == j[1] and i[0] != i[1]:\n",
        "                bio_labels.append('B-' + j[0])\n",
        "                break\n",
        "            elif i[0] > j[1] and i[1] <= j[2] and i[0] != i[1]:\n",
        "                bio_labels.append('I-' + j[0])\n",
        "                break\n",
        "        else: \n",
        "            bio_labels.append('O')\n",
        "    return tokens, bio_labels, spans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M4Yyr5VIYSK"
      },
      "source": [
        "#### Считывание всех данных из директории"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9rmXzafuIiCD"
      },
      "outputs": [],
      "source": [
        "def all_read(dir, tokenizer):\n",
        "    tokens = []\n",
        "    labels = []\n",
        "    spans = []\n",
        "    names = {name[:-4] for name in os.listdir(dir)}\n",
        "    for name in names:\n",
        "        token, label, span = bio(dir + '/' + name + '.txt', dir + '/' + name + '.ann', tokenizer)\n",
        "        tokens.append(token)\n",
        "        labels.append(label)\n",
        "        spans.append(span)\n",
        "    return tokens, labels, spans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBkwQBEwKS02"
      },
      "source": [
        "# Считывание всех данных в BIO-разметку"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Frz974KW_G"
      },
      "source": [
        "#### Создание токенизатора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6ezUUF87KdJr"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQgQL_oDKhvv"
      },
      "source": [
        "#### Создание train, dev, test частей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8T9PdTsPKm5T"
      },
      "outputs": [],
      "source": [
        "TRAIN_TOKENS, TRAIN_LABELS, TRAIN_SPANS = all_read('train', tokenizer)\n",
        "DEV_TOKENS, DEV_LABELS, DEV_SPANS = all_read('dev', tokenizer)\n",
        "TEST_TOKENS, TEST_LABELS, TEST_SPANS = all_read('test', tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKhU6ofeLvwV"
      },
      "source": [
        "# Подготовка словарей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A0YurWBsHtx7"
      },
      "outputs": [],
      "source": [
        "token2cnt = Counter([token for sentence in TRAIN_TOKENS for token in sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h6QsuxTVMIDv"
      },
      "outputs": [],
      "source": [
        "def get_token2idx(\n",
        "    token2cnt: Dict[str, int],\n",
        "    min_count: int,\n",
        ") -> Dict[str, int]:\n",
        "    \"\"\"\n",
        "    Get mapping from tokens to indices to use with Embedding layer.\n",
        "    \"\"\"\n",
        "\n",
        "    token2idx: Dict[str, int] = {}\n",
        "    token2idx.update({'<PAD>': 0, '<UNK>': 1})\n",
        "\n",
        "    idx = 2\n",
        "    for token, token_frequency in tqdm(token2cnt.items()):\n",
        "        if token_frequency >= min_count:\n",
        "            token2idx[token] = idx\n",
        "            idx += 1\n",
        "\n",
        "    return token2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PuAtlPUMfP_",
        "outputId": "9a7d2515-88ed-42ea-aa22-192d7e34ca00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31282/31282 [00:00<00:00, 611259.39it/s]\n"
          ]
        }
      ],
      "source": [
        "token2idx = get_token2idx(token2cnt, min_count=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r67E0zYVMhAQ"
      },
      "outputs": [],
      "source": [
        "# Функция для сортировки тегов, чтобы сначала был тег O, потом теги B- и только после теги I-\n",
        "\n",
        "def sort_labels_func(x: str) -> int:\n",
        "    if x == \"O\":\n",
        "        return 0\n",
        "    elif x.startswith(\"B-\"):\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "label_set = sorted(\n",
        "    set(label for sentence in TRAIN_LABELS for label in sentence),\n",
        "    key=lambda x: (sort_labels_func(x), x),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kXLGkBbMM0zv"
      },
      "outputs": [],
      "source": [
        "def get_label2idx(label_set: List[str]) -> Dict[str, int]:\n",
        "    \"\"\"\n",
        "    Get mapping from labels to indices.\n",
        "    \"\"\"\n",
        "\n",
        "    label2idx: Dict[str, int] = {label: idx for idx, label in tqdm(enumerate(label_set))}\n",
        "\n",
        "    return label2idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A4g9xhAMpwc",
        "outputId": "09e09e79-c364-42fb-a394-a94b18e92287"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "59it [00:00, 57549.75it/s]\n"
          ]
        }
      ],
      "source": [
        "label2idx = get_label2idx(label_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-UqsWZyNZ29"
      },
      "source": [
        "# Подготовка датасета и загрузчика"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B3loLWeRNELB"
      },
      "outputs": [],
      "source": [
        "class NERDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for NER.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        token_seq: List[List[str]],\n",
        "        label_seq: List[List[str]],\n",
        "        token2idx: Dict[str, int],\n",
        "        label2idx: Dict[str, int],\n",
        "    ):\n",
        "        self.token2idx = token2idx\n",
        "        self.label2idx = label2idx\n",
        "\n",
        "        self.token_seq = [self.process_tokens(tokens, token2idx) for tokens in token_seq]\n",
        "        self.label_seq = [self.process_labels(labels, label2idx) for labels in label_seq]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_seq)\n",
        "\n",
        "    def __getitem__(\n",
        "        self,\n",
        "        idx: int,\n",
        "    ) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
        "        return (\n",
        "            torch.LongTensor(self.token_seq[idx]),\n",
        "            torch.LongTensor(self.label_seq[idx])\n",
        "        )\n",
        "    \n",
        "    @staticmethod\n",
        "    def process_tokens(\n",
        "        tokens: List[str],\n",
        "        token2idx: Dict[str, int],\n",
        "        unk: str = \"<UNK>\",\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Transform list of tokens into list of tokens' indices.\n",
        "        \"\"\"\n",
        "        result = [\n",
        "            token2idx[token] if token in token2idx else token2idx[unk]\n",
        "            for token in tokens\n",
        "        ]\n",
        "        return result\n",
        "\n",
        "    @staticmethod\n",
        "    def process_labels(\n",
        "        labels: List[str],\n",
        "        label2idx: Dict[str, int],\n",
        "    ) -> List[int]:\n",
        "        \"\"\"\n",
        "        Transform list of labels into list of labels' indices.\n",
        "        \"\"\"\n",
        "        result = [label2idx[label] for label in labels]\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C3B8xOiNooe"
      },
      "source": [
        "#### Создание 3 датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2BWp3upINrce"
      },
      "outputs": [],
      "source": [
        "train_dataset = NERDataset(\n",
        "    token_seq=TRAIN_TOKENS,\n",
        "    label_seq=TRAIN_LABELS,\n",
        "    token2idx=token2idx,\n",
        "    label2idx=label2idx,\n",
        ")\n",
        "valid_dataset = NERDataset(\n",
        "    token_seq=DEV_TOKENS,\n",
        "    label_seq=DEV_LABELS,\n",
        "    token2idx=token2idx,\n",
        "    label2idx=label2idx,\n",
        ")\n",
        "test_dataset = NERDataset(\n",
        "    token_seq=TEST_TOKENS,\n",
        "    label_seq=TEST_LABELS,\n",
        "    token2idx=token2idx,\n",
        "    label2idx=label2idx,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV0z8uW5N_Qh"
      },
      "source": [
        "#### Создание Коллатора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GSBdM1H0N0_r"
      },
      "outputs": [],
      "source": [
        "class NERCollator:\n",
        "    \"\"\"\n",
        "    Collator that handles variable-size sentences.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        token_padding_value: int,\n",
        "        label_padding_value: int,\n",
        "    ):\n",
        "        self.token_padding_value = token_padding_value\n",
        "        self.label_padding_value = label_padding_value\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        batch: List[Tuple[torch.LongTensor, torch.LongTensor]],\n",
        "    ):\n",
        "\n",
        "        tokens, labels = zip(*batch)\n",
        "\n",
        "        tokens = torch.nn.utils.rnn.pad_sequence(tokens, batch_first=True, padding_value=self.token_padding_value)\n",
        "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=self.label_padding_value)\n",
        "\n",
        "        return {\"input_ids\": tokens, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "y_xLnRp7ODXM"
      },
      "outputs": [],
      "source": [
        "collator = NERCollator(\n",
        "    token_padding_value=token2idx[\"<PAD>\"],\n",
        "    label_padding_value=-100,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU8gd9aYYEmK"
      },
      "source": [
        "# Создание, обучение и сохранение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXgzTlztOFKc",
        "outputId": "6ca68420-b092-4808-de52-3dd19dc7da1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"cointegrated/rubert-tiny2\", num_labels=len(label_set))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "awbvgJ8IX7mn"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=os.getcwd()+'/output_model',\n",
        "    learning_rate=8e-5,\n",
        "    weight_decay=1e-3,\n",
        "    lr_scheduler_type='cosine',\n",
        "    full_determinism=False,\n",
        "    seed=42,\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=42,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=500,\n",
        "    save_steps=5000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YYol9va5YPGP"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "HgLNzyTkYQk-",
        "outputId": "b27da2df-c4de-4634-8618-2e403c740685"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 746\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3730\n",
            "  Number of trainable parameters = 29114579\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3730' max='3730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3730/3730 01:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.759600</td>\n",
              "      <td>1.496149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.233100</td>\n",
              "      <td>1.199375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.969600</td>\n",
              "      <td>1.113023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.789800</td>\n",
              "      <td>1.059876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.695700</td>\n",
              "      <td>1.032367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.626400</td>\n",
              "      <td>1.028914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.590800</td>\n",
              "      <td>1.038841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 94\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 94\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 94\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 94\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 94\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 94\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 94\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3730, training_loss=0.9297234788337277, metrics={'train_runtime': 113.5704, 'train_samples_per_second': 65.686, 'train_steps_per_second': 32.843, 'total_flos': 40133599192596.0, 'train_loss': 0.9297234788337277, 'epoch': 10.0})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RRlHBgUcODr"
      },
      "source": [
        "#### Сохранение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nc_5RxTcYWbI"
      },
      "outputs": [],
      "source": [
        "final = unwrap_model(trainer.model_wrapped)\n",
        "final = final.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GWDWH7KZbq3B"
      },
      "outputs": [],
      "source": [
        "def compress_data(data):\n",
        "    return lzma.compress(\n",
        "        pickle.dumps(data), \n",
        "        format=lzma.FORMAT_RAW, \n",
        "        filters=[{\"id\":lzma.FILTER_LZMA2,\"dict_size\":268435456, \"preset\":9, \"mf\":lzma.MF_HC3, \"depth\":0, \"lc\":3}]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "m1hpy4J6csr_"
      },
      "outputs": [],
      "source": [
        "compressed_state = compress_data(final.state_dict())\n",
        "compressed_config = compress_data(final.config)\n",
        "\n",
        "with open(\"state.xz\", \"wb\") as f:\n",
        "    f.write(compressed_state)\n",
        "\n",
        "with open(\"config.xz\", \"wb\") as f:\n",
        "    f.write(compressed_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eLnbONiQc9w1"
      },
      "outputs": [],
      "source": [
        "idx2label = {}\n",
        "for key, val in label2idx.items():\n",
        "    idx2label[val] = key\n",
        "\n",
        "with open('token2idx.pkl', 'wb') as f:\n",
        "    pickle.dump(token2idx, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('idx2label.pkl', 'wb') as g:\n",
        "    pickle.dump(idx2label, g, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "604628d2719fd283e1f8d51ef93436f33b0d89f8198165442588855efe9829f8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
